{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d3f8af0-789a-4873-ab0b-975f204a678e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[20 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m fatal: not a git repository (or any of the parent directories): .git\n",
      "  \u001b[31m   \u001b[0m /tmp/pip-install-ontf52ra/flash-attn_f113d49e433f41a3a2afc2c7abd24c73/setup.py:78: UserWarning: flash_attn was requested, but nvcc was not found.  Are you sure your environment has nvcc available?  If you're installing within a container from https://hub.docker.com/r/pytorch/pytorch, only images whose names contain 'devel' will provide nvcc.\n",
      "  \u001b[31m   \u001b[0m   warnings.warn(\n",
      "  \u001b[31m   \u001b[0m Traceback (most recent call last):\n",
      "  \u001b[31m   \u001b[0m   File \"<string>\", line 2, in <module>\n",
      "  \u001b[31m   \u001b[0m   File \"<pip-setuptools-caller>\", line 34, in <module>\n",
      "  \u001b[31m   \u001b[0m   File \"/tmp/pip-install-ontf52ra/flash-attn_f113d49e433f41a3a2afc2c7abd24c73/setup.py\", line 133, in <module>\n",
      "  \u001b[31m   \u001b[0m     CUDAExtension(\n",
      "  \u001b[31m   \u001b[0m   File \"/home/ismail/envs/hym/lib/python3.10/site-packages/torch/utils/cpp_extension.py\", line 1076, in CUDAExtension\n",
      "  \u001b[31m   \u001b[0m     library_dirs += library_paths(cuda=True)\n",
      "  \u001b[31m   \u001b[0m   File \"/home/ismail/envs/hym/lib/python3.10/site-packages/torch/utils/cpp_extension.py\", line 1203, in library_paths\n",
      "  \u001b[31m   \u001b[0m     if (not os.path.exists(_join_cuda_home(lib_dir)) and\n",
      "  \u001b[31m   \u001b[0m   File \"/home/ismail/envs/hym/lib/python3.10/site-packages/torch/utils/cpp_extension.py\", line 2416, in _join_cuda_home\n",
      "  \u001b[31m   \u001b[0m     raise OSError('CUDA_HOME environment variable is not set. '\n",
      "  \u001b[31m   \u001b[0m OSError: CUDA_HOME environment variable is not set. Please set it to your CUDA install root.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m torch.__version__  = 2.1.2+cu121\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
      "\n",
      "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
      "\u001b[31m╰─>\u001b[0m See above for output.\n",
      "\n",
      "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
      "\u001b[1;36mhint\u001b[0m: See above for details.\n",
      "Requirement already satisfied: gradio in /home/ismail/envs/hym/lib/python3.10/site-packages (4.14.0)\n",
      "Requirement already satisfied: python-multipart in /home/ismail/envs/hym/lib/python3.10/site-packages (from gradio) (0.0.6)\n",
      "Requirement already satisfied: pydantic>=2.0 in /home/ismail/envs/hym/lib/python3.10/site-packages (from gradio) (2.5.3)\n",
      "Requirement already satisfied: semantic-version~=2.0 in /home/ismail/envs/hym/lib/python3.10/site-packages (from gradio) (2.10.0)\n",
      "Requirement already satisfied: tomlkit==0.12.0 in /home/ismail/envs/hym/lib/python3.10/site-packages (from gradio) (0.12.0)\n",
      "Requirement already satisfied: uvicorn>=0.14.0 in /home/ismail/envs/hym/lib/python3.10/site-packages (from gradio) (0.25.0)\n",
      "Requirement already satisfied: altair<6.0,>=4.2.0 in /home/ismail/envs/hym/lib/python3.10/site-packages (from gradio) (5.2.0)\n",
      "Requirement already satisfied: pydub in /home/ismail/envs/hym/lib/python3.10/site-packages (from gradio) (0.25.1)\n",
      "Requirement already satisfied: pyyaml<7.0,>=5.0 in /home/ismail/envs/hym/lib/python3.10/site-packages (from gradio) (6.0.1)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in /home/ismail/envs/hym/lib/python3.10/site-packages (from gradio) (4.9.0)\n",
      "Requirement already satisfied: aiofiles<24.0,>=22.0 in /home/ismail/envs/hym/lib/python3.10/site-packages (from gradio) (23.2.1)\n",
      "Requirement already satisfied: orjson~=3.0 in /home/ismail/envs/hym/lib/python3.10/site-packages (from gradio) (3.9.10)\n",
      "Requirement already satisfied: httpx in /home/ismail/envs/hym/lib/python3.10/site-packages (from gradio) (0.26.0)\n",
      "Requirement already satisfied: matplotlib~=3.0 in /home/ismail/envs/hym/lib/python3.10/site-packages (from gradio) (3.8.2)\n",
      "Requirement already satisfied: numpy~=1.0 in /home/ismail/envs/hym/lib/python3.10/site-packages (from gradio) (1.22.0)\n",
      "Requirement already satisfied: jinja2<4.0 in /home/ismail/envs/hym/lib/python3.10/site-packages (from gradio) (3.1.3)\n",
      "Requirement already satisfied: typer[all]<1.0,>=0.9 in /home/ismail/envs/hym/lib/python3.10/site-packages (from gradio) (0.9.0)\n",
      "Requirement already satisfied: pillow<11.0,>=8.0 in /home/ismail/envs/hym/lib/python3.10/site-packages (from gradio) (10.2.0)\n",
      "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /home/ismail/envs/hym/lib/python3.10/site-packages (from gradio) (6.1.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.19.3 in /home/ismail/envs/hym/lib/python3.10/site-packages (from gradio) (0.20.2)\n",
      "Requirement already satisfied: gradio-client==0.8.0 in /home/ismail/envs/hym/lib/python3.10/site-packages (from gradio) (0.8.0)\n",
      "Requirement already satisfied: packaging in /home/ismail/envs/hym/lib/python3.10/site-packages (from gradio) (23.2)\n",
      "Requirement already satisfied: fastapi in /home/ismail/envs/hym/lib/python3.10/site-packages (from gradio) (0.109.0)\n",
      "Requirement already satisfied: pandas<3.0,>=1.0 in /home/ismail/envs/hym/lib/python3.10/site-packages (from gradio) (1.5.3)\n",
      "Requirement already satisfied: ffmpy in /home/ismail/envs/hym/lib/python3.10/site-packages (from gradio) (0.3.1)\n",
      "Requirement already satisfied: markupsafe~=2.0 in /home/ismail/envs/hym/lib/python3.10/site-packages (from gradio) (2.1.3)\n",
      "Requirement already satisfied: fsspec in /home/ismail/envs/hym/lib/python3.10/site-packages (from gradio-client==0.8.0->gradio) (2023.10.0)\n",
      "Requirement already satisfied: websockets<12.0,>=10.0 in /home/ismail/envs/hym/lib/python3.10/site-packages (from gradio-client==0.8.0->gradio) (11.0.3)\n",
      "Requirement already satisfied: toolz in /home/ismail/envs/hym/lib/python3.10/site-packages (from altair<6.0,>=4.2.0->gradio) (0.12.0)\n",
      "Requirement already satisfied: jsonschema>=3.0 in /home/ismail/envs/hym/lib/python3.10/site-packages (from altair<6.0,>=4.2.0->gradio) (4.20.0)\n",
      "Requirement already satisfied: requests in /home/ismail/envs/hym/lib/python3.10/site-packages (from huggingface-hub>=0.19.3->gradio) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /home/ismail/envs/hym/lib/python3.10/site-packages (from huggingface-hub>=0.19.3->gradio) (4.66.1)\n",
      "Requirement already satisfied: filelock in /home/ismail/envs/hym/lib/python3.10/site-packages (from huggingface-hub>=0.19.3->gradio) (3.13.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/ismail/envs/hym/lib/python3.10/site-packages (from matplotlib~=3.0->gradio) (4.47.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/ismail/envs/hym/lib/python3.10/site-packages (from matplotlib~=3.0->gradio) (0.12.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/ismail/envs/hym/lib/python3.10/site-packages (from matplotlib~=3.0->gradio) (2.8.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/ismail/envs/hym/lib/python3.10/site-packages (from matplotlib~=3.0->gradio) (1.2.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/ismail/envs/hym/lib/python3.10/site-packages (from matplotlib~=3.0->gradio) (1.4.5)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/ismail/envs/hym/lib/python3.10/site-packages (from matplotlib~=3.0->gradio) (3.1.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ismail/envs/hym/lib/python3.10/site-packages (from pandas<3.0,>=1.0->gradio) (2023.3.post1)\n",
      "Requirement already satisfied: pydantic-core==2.14.6 in /home/ismail/envs/hym/lib/python3.10/site-packages (from pydantic>=2.0->gradio) (2.14.6)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /home/ismail/envs/hym/lib/python3.10/site-packages (from pydantic>=2.0->gradio) (0.6.0)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /home/ismail/envs/hym/lib/python3.10/site-packages (from typer[all]<1.0,>=0.9->gradio) (8.1.7)\n",
      "Requirement already satisfied: colorama<0.5.0,>=0.4.3 in /home/ismail/envs/hym/lib/python3.10/site-packages (from typer[all]<1.0,>=0.9->gradio) (0.4.6)\n",
      "Requirement already satisfied: shellingham<2.0.0,>=1.3.0 in /home/ismail/envs/hym/lib/python3.10/site-packages (from typer[all]<1.0,>=0.9->gradio) (1.5.4)\n",
      "Requirement already satisfied: rich<14.0.0,>=10.11.0 in /home/ismail/envs/hym/lib/python3.10/site-packages (from typer[all]<1.0,>=0.9->gradio) (13.7.0)\n",
      "Requirement already satisfied: h11>=0.8 in /home/ismail/envs/hym/lib/python3.10/site-packages (from uvicorn>=0.14.0->gradio) (0.14.0)\n",
      "Requirement already satisfied: starlette<0.36.0,>=0.35.0 in /home/ismail/envs/hym/lib/python3.10/site-packages (from fastapi->gradio) (0.35.1)\n",
      "Requirement already satisfied: certifi in /home/ismail/envs/hym/lib/python3.10/site-packages (from httpx->gradio) (2023.11.17)\n",
      "Requirement already satisfied: anyio in /home/ismail/envs/hym/lib/python3.10/site-packages (from httpx->gradio) (4.2.0)\n",
      "Requirement already satisfied: idna in /home/ismail/envs/hym/lib/python3.10/site-packages (from httpx->gradio) (3.6)\n",
      "Requirement already satisfied: httpcore==1.* in /home/ismail/envs/hym/lib/python3.10/site-packages (from httpx->gradio) (1.0.2)\n",
      "Requirement already satisfied: sniffio in /home/ismail/envs/hym/lib/python3.10/site-packages (from httpx->gradio) (1.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /home/ismail/envs/hym/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (2023.12.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /home/ismail/envs/hym/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.16.2)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /home/ismail/envs/hym/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.32.1)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /home/ismail/envs/hym/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (23.2.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/ismail/envs/hym/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/ismail/envs/hym/lib/python3.10/site-packages (from rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio) (2.17.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/ismail/envs/hym/lib/python3.10/site-packages (from rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio) (3.0.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/ismail/envs/hym/lib/python3.10/site-packages (from anyio->httpx->gradio) (1.2.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ismail/envs/hym/lib/python3.10/site-packages (from requests->huggingface-hub>=0.19.3->gradio) (2.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ismail/envs/hym/lib/python3.10/site-packages (from requests->huggingface-hub>=0.19.3->gradio) (3.3.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/ismail/envs/hym/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install -q insanely-fast-whisper\n",
    "!pip install -q flash-attn --no-build-isolation\n",
    "!pip install gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d85ad45-f4a2-46d8-85f7-2db0a505ec5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! sudo apt install ffmpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23205b16-d109-4035-b889-d8b0545c8b7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wheel in /home/ismail/envs/hym/lib/python3.10/site-packages (0.42.0)\n"
     ]
    }
   ],
   "source": [
    "! pip3 install wheel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95074ea4-64f3-4fab-bc36-0d2b01d98955",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install insanely-fast-whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9eea934e-4258-4cfd-84f0-85386358e84a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ismail/envs/hym/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline\n",
    "from optimum.bettertransformer import BetterTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed5b6b79-c0fc-4d96-9159-02b774947d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch_dtype = torch.float16 if torch.cuda.is_available() else torch.float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70ff5d62-c2f5-48e0-afa1-a4f69a14ad72",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "model_id = \"distil-whisper/distil-medium.en\"\n",
    "\n",
    "model = AutoModelForSpeechSeq2Seq.from_pretrained(\n",
    "    model_id, torch_dtype=torch_dtype, low_cpu_mem_usage=True, use_safetensors=True# , use_flash_attention_2=True\n",
    ")\n",
    "model.to(device)\n",
    "# model = model.to_bettertransformer() # we are using optimum BetterTransformer since Flash Attention 2 isn't supported on Colab\n",
    "processor = AutoProcessor.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8e2aa0e-2c81-4417-a3b8-1fc9c0134f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = pipeline(\n",
    "    \"automatic-speech-recognition\",\n",
    "    model=model,\n",
    "    tokenizer=processor.tokenizer,\n",
    "    feature_extractor=processor.feature_extractor,\n",
    "    max_new_tokens=128,\n",
    "    chunk_length_s=15, #long form transcription\n",
    "    batch_size=16,\n",
    "    torch_dtype=torch_dtype,\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c9873b82-3748-48c3-aeaa-35e9f9a7a1a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyboard interruption in main thread... closing server.\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "from transformers import pipeline\n",
    "import numpy as np\n",
    "\n",
    "def transcribe(filepath):\n",
    "    output = pipe(\n",
    "        filepath,\n",
    "    )\n",
    "    return output[\"text\"]\n",
    "\n",
    "\n",
    "import gradio as gr\n",
    "\n",
    "demo = gr.Interface(\n",
    "    title='My Audio Transcription App Powered by Distill Whisper',\n",
    "    description=\"Start recording\",\n",
    "    fn=transcribe,\n",
    "    inputs=gr.Audio(sources=[\"upload\", \"microphone\"], type=\"filepath\"),\n",
    "    outputs= \"text\",\n",
    ")\n",
    "\n",
    "demo.launch(debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0035fbec-e052-4efe-ab31-9aecfeb13073",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing server running on port: 7860\n",
      "Running on local URL:  http://127.0.0.1:7861\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyboard interruption in main thread... closing server.\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "from transformers import pipeline\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def transcribe(filepath):\n",
    "    output = pipe(\n",
    "        filepath,\n",
    "    )\n",
    "    return output[\"text\"]\n",
    "\n",
    "\n",
    "def transcribe_streaming(stream, new_chunk):\n",
    "    sr, y = new_chunk\n",
    "    y = y.astype(np.float32)\n",
    "    y /= np.max(np.abs(y))\n",
    "\n",
    "    if stream is not None:\n",
    "        stream = np.concatenate([stream, y])\n",
    "    else:\n",
    "        stream = y\n",
    "    return stream, pipe({\"sampling_rate\": sr, \"raw\": stream})[\"text\"]\n",
    "\n",
    "\n",
    "import gradio as gr\n",
    "\n",
    "demo = gr.Blocks()\n",
    "\n",
    "mic_transcribe = gr.Interface(\n",
    "    title='My Audio Transcription App Powered by Distill Whisper',\n",
    "    description=\"Start recording\",\n",
    "    fn=transcribe_streaming,\n",
    "    inputs=[\"state\", gr.Audio(sources=\"microphone\", streaming=True)],\n",
    "    outputs=[\"state\", \"text\"],\n",
    "    live=True,\n",
    ")\n",
    "\n",
    "\n",
    "file_transcribe = gr.Interface(\n",
    "    title='My Audio Transcription App Powered by Distill Whisper',\n",
    "    description=\"Upload an audio file\",\n",
    "    fn=transcribe,\n",
    "    inputs=gr.Audio(sources=\"upload\", type=\"filepath\"),\n",
    "    outputs=gr.Textbox(),\n",
    ")\n",
    "\n",
    "\n",
    "gr.close_all()\n",
    "\n",
    "with demo:\n",
    "    gr.TabbedInterface(\n",
    "        [file_transcribe, mic_transcribe],\n",
    "        [ \"Transcribe Audio File\", \"Transcribe Microphone\"],\n",
    "    )\n",
    "\n",
    "demo.launch(debug=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c84bca9-b3fe-49e7-82cc-de612f677bff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
